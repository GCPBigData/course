{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TFvsKerasvsTFlearn_MNIST.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"j7a4139FPMIc","colab_type":"text"},"cell_type":"markdown","source":["# Comparison of Pure TensorFlow, Keras and TF Learn"]},{"metadata":{"id":"PWEfDAEePLJW","colab_type":"text"},"cell_type":"markdown","source":["In this notebook we are going to present the same problem being solved in three different ways. In all the cases, TensorFlow is going to be used as backend. The main difference is that two high levels API are going to be evaluated and compared each other and also with the original TensorFlow implementation. The problem to be solved is the classic MNIST. First we are goig to implement in TensorFlow, next in Keras and finally in TFLearn. In the end, a summary of the pros and cons of each is discussed. \n","\n","## Input Data"]},{"metadata":{"id":"_TFDE7Sh7FBQ","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"tcrP6tNb7Dtf","colab_type":"text"},"cell_type":"markdown","source":["## Implementation in TensorFlow"]},{"metadata":{"id":"oHuK4jUBPKls","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":802},"outputId":"ec3a2444-5439-4f4f-bd41-10498b096162","executionInfo":{"status":"ok","timestamp":1536673555093,"user_tz":-180,"elapsed":20982,"user":{"displayName":"Fernando Marcos Wittmann","photoUrl":"//lh5.googleusercontent.com/-IMybAdFO0xk/AAAAAAAAAAI/AAAAAAAAUuE/YzSiSBdfaIc/s50-c-k-no/photo.jpg","userId":"105799216615715799941"}}},"cell_type":"code","source":["# Import MNIST data\n","from tensorflow.examples.tutorials.mnist import input_data\n","mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n","\n","import tensorflow as tf\n","\n","# Parameters\n","learning_rate = 0.1\n","num_steps = 500\n","batch_size = 128\n","display_step = 100\n","\n","# Network Parameters\n","n_hidden_1 = 128 # 1st layer number of neurons\n","n_hidden_2 = 512 # 2nd layer number of neurons\n","num_input = 784 # MNIST data input (img shape: 28*28)\n","num_classes = 10 # MNIST total classes (0-9 digits)\n","\n","# tf Graph input\n","X = tf.placeholder(\"float\", [None, num_input])\n","Y = tf.placeholder(\"float\", [None, num_classes])\n","\n","# Store layers weight & bias\n","weights = {\n","    'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n","    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n","    'out': tf.Variable(tf.random_normal([n_hidden_2, num_classes]))\n","}\n","biases = {\n","    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n","    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n","    'out': tf.Variable(tf.random_normal([num_classes]))\n","}\n","\n","# Create model\n","def neural_net(x):\n","    # Hidden fully connected layer with 256 neurons\n","    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n","    # Hidden fully connected layer with 256 neurons\n","    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n","    # Output fully connected layer with a neuron for each class\n","    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n","    return out_layer\n","  \n","# Construct model\n","logits = neural_net(X)\n","\n","# Define loss and optimizer\n","loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n","    logits=logits, labels=Y))\n","optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n","train_op = optimizer.minimize(loss_op)\n","\n","# Evaluate model (with test logits, for dropout to be disabled)\n","correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n","accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n","\n","# Initialize the variables (i.e. assign their default value)\n","init = tf.global_variables_initializer()\n","\n","# Start training\n","with tf.Session() as sess:\n","\n","    # Run the initializer\n","    sess.run(init)\n","\n","    for step in range(1, num_steps+1):\n","        batch_x, batch_y = mnist.train.next_batch(batch_size)\n","        # Run optimization op (backprop)\n","        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n","        if step % display_step == 0 or step == 1:\n","            # Calculate batch loss and accuracy\n","            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n","                                                                 Y: batch_y})\n","            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n","                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n","                  \"{:.3f}\".format(acc))\n","\n","    print(\"Optimization Finished!\")\n","\n","    # Calculate accuracy for MNIST test images\n","    print(\"Testing Accuracy:\", \\\n","        sess.run(accuracy, feed_dict={X: mnist.test.images,\n","                                      Y: mnist.test.labels}))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-3-6671dde29ec9>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please write your own downloading logic.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use urllib or similar directly.\n","Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting /tmp/data/train-images-idx3-ubyte.gz\n","Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting /tmp/data/train-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.one_hot on tensors.\n","Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n","Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n","Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n","Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","WARNING:tensorflow:From <ipython-input-3-6671dde29ec9>:49: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n","\n","Step 1, Minibatch Loss= 7203.2021, Training Accuracy= 0.562\n","Step 100, Minibatch Loss= 412.8487, Training Accuracy= 0.859\n","Step 200, Minibatch Loss= 327.3063, Training Accuracy= 0.852\n","Step 300, Minibatch Loss= 128.3178, Training Accuracy= 0.844\n","Step 400, Minibatch Loss= 47.7142, Training Accuracy= 0.883\n","Step 500, Minibatch Loss= 125.0990, Training Accuracy= 0.875\n","Optimization Finished!\n","Testing Accuracy: 0.8434\n"],"name":"stdout"}]},{"metadata":{"id":"ecABSXV1VU6k","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"KPiwW_lsQXV8","colab_type":"text"},"cell_type":"markdown","source":["## Implementation in Keras"]},{"metadata":{"id":"q_HLLGr6QZCZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":255},"outputId":"fc97e062-89b0-4cbe-a876-c69b55b13f7a","executionInfo":{"status":"ok","timestamp":1536673695672,"user_tz":-180,"elapsed":55675,"user":{"displayName":"Fernando Marcos Wittmann","photoUrl":"//lh5.googleusercontent.com/-IMybAdFO0xk/AAAAAAAAAAI/AAAAAAAAUuE/YzSiSBdfaIc/s50-c-k-no/photo.jpg","userId":"105799216615715799941"}}},"cell_type":"code","source":["import tensorflow as tf\n","mnist = tf.keras.datasets.mnist\n","\n","(x_train, y_train),(x_test, y_test) = mnist.load_data()\n","x_train, x_test = x_train / 255.0, x_test / 255.0\n","\n","model = tf.keras.models.Sequential([\n","  tf.keras.layers.Flatten(),\n","  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n","  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n","  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n","])\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.fit(x_train, y_train, epochs=5)\n","test_accuracy = model.evaluate(x_test, y_test)[1]\n","print(\"Test accuracy: {}\".format(test_accuracy))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","Epoch 1/5\n","60000/60000 [==============================] - 11s 177us/step - loss: 0.2158 - acc: 0.9343\n","Epoch 2/5\n","60000/60000 [==============================] - 10s 173us/step - loss: 0.0926 - acc: 0.9711\n","Epoch 3/5\n","60000/60000 [==============================] - 10s 174us/step - loss: 0.0641 - acc: 0.9804\n","Epoch 4/5\n","60000/60000 [==============================] - 10s 175us/step - loss: 0.0505 - acc: 0.9838\n","Epoch 5/5\n","60000/60000 [==============================] - 11s 175us/step - loss: 0.0401 - acc: 0.9876\n","10000/10000 [==============================] - 1s 53us/step\n","Test accuracy: 0.9764\n"],"name":"stdout"}]},{"metadata":{"id":"3ynXVkIhYl9Y","colab_type":"text"},"cell_type":"markdown","source":["## Implementation in TFLearn"]},{"metadata":{"id":"mRCavd1bQZje","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"97be64c4-f562-486b-99e4-fc80ef87072a","executionInfo":{"status":"ok","timestamp":1536674052075,"user_tz":-180,"elapsed":1291,"user":{"displayName":"Fernando Marcos Wittmann","photoUrl":"//lh5.googleusercontent.com/-IMybAdFO0xk/AAAAAAAAAAI/AAAAAAAAUuE/YzSiSBdfaIc/s50-c-k-no/photo.jpg","userId":"105799216615715799941"}}},"cell_type":"code","source":["!pip install tflearn\n","\n","import tensorflow as tf\n","import tflearn\n","import tflearn.datasets.mnist as mnist\n","\n","X_train, y_train, X_test, y_test = mnist.load_data(one_hot=True)\n","\n","net = tflearn.input_data([None, 784])\n","net = tflearn.fully_connected(net, 128, activation='ReLU')\n","net = tflearn.fully_connected(net, 512, activation='ReLU')\n","net = tflearn.fully_connected(net, 10, activation='softmax')\n","net = tflearn.regression(net,\n","                         optimizer='sgd',\n","                         learning_rate=0.1,\n","                         loss='categorical_crossentropy')\n","\n","model = tflearn.DNN(net)\n","model.fit(X_train, y_train,\n","          validation_set=0.1, show_metric=True, batch_size=100, n_epoch=5)\n","\n","test_accuracy = model.evaluate(X_test, y_test)\n","print(\"Test accuracy: \", test_accuracy)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Training Step: 2474  | total loss: \u001b[1m\u001b[32m0.11723\u001b[0m\u001b[0m | time: 4.569s\n","| SGD | epoch: 005 | loss: 0.11723 - acc: 0.9696 -- iter: 49400/49500\n","Training Step: 2475  | total loss: \u001b[1m\u001b[32m0.11746\u001b[0m\u001b[0m | time: 5.596s\n","| SGD | epoch: 005 | loss: 0.11746 - acc: 0.9697 | val_loss: 0.15667 - val_acc: 0.9551 -- iter: 49500/49500\n","--\n","Test accuracy:  [0.9601]\n"],"name":"stdout"}]},{"metadata":{"id":"yjsXL4KUcghi","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"PLtp_Rf28ZTT","colab_type":"text"},"cell_type":"markdown","source":["## Textual Quiz\n","\n","### Setup code\n","Please execute the following line of code so that your answer in the quizes can be checked:"]},{"metadata":{"id":"Mg15rUrh8YM7","colab_type":"code","colab":{}},"cell_type":"code","source":["from base64 import b64encode, b64decode\n","\n","encoded_answer = {}\n","encoded_answer[1] = b'eydhJzogJycsICdiJzogJyd9'\n","\n","def check_answer(students_answer, question, see_correct_answer=False):\n","  if see_correct_answer:\n","    expected_answer = b64decode(encoded_answer[question]).decode('utf-8')\n","    print(\"The expected answer is {}\".format(expected_answer))\n","  else:\n","    if b64encode(str(students_answer).lower().strip().encode('utf-8')) == encoded_answer[question]:\n","      print('You got it right!')\n","    else:\n","      print(\"Please try again!\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_v0q1hJMDamA","colab_type":"code","colab":{}},"cell_type":"code","source":["def encode_answer(a):\n","  print(b64encode(str(a).lower().strip().encode('utf-8')))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"T9NNlkUz9qgP","colab_type":"text"},"cell_type":"markdown","source":["\n","### Question 1) Please fill the gaps in the following definitions:\n","- Each iteration from a neural network is called 'a'\n","- A sample drawn from a dataset for each iteration in a neural network is called 'b'\n","\n","Please answer to what 'a' and 'b' stands for below (example: `{'a': 'neural network', 'b':'True'}`:\n"]},{"metadata":{"id":"je6q-3Nm0EnF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6b54e1dc-0f22-4161-d5a1-56d91a6f54a3","executionInfo":{"status":"ok","timestamp":1536674100299,"user_tz":-180,"elapsed":896,"user":{"displayName":"Fernando Marcos Wittmann","photoUrl":"//lh5.googleusercontent.com/-IMybAdFO0xk/AAAAAAAAAAI/AAAAAAAAUuE/YzSiSBdfaIc/s50-c-k-no/photo.jpg","userId":"105799216615715799941"}}},"cell_type":"code","source":["# TODO: Please answer Question 1 below )\n","reply = {'a':'', 'b':''}\n","\n","# Check if your answer is correct. Change see_correct_answer to 'True' to see expected answer \n","check_answer(reply, question=1, see_correct_answer=False)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["You got it right!\n"],"name":"stdout"}]},{"metadata":{"id":"xFV9LWoqDqDx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"c1d7017a-5841-4940-e879-cb0b0416a37d","executionInfo":{"status":"ok","timestamp":1536592778452,"user_tz":-180,"elapsed":1131,"user":{"displayName":"Fernando Marcos Wittmann","photoUrl":"//lh5.googleusercontent.com/-IMybAdFO0xk/AAAAAAAAAAI/AAAAAAAAUuE/YzSiSBdfaIc/s50-c-k-no/photo.jpg","userId":"105799216615715799941"}}},"cell_type":"code","source":["encode_answer(str({'a':'', 'b':''}))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["b'eydhJzogJycsICdiJzogJyd9'\n"],"name":"stdout"}]},{"metadata":{"id":"3RO3N7V59ttb","colab_type":"text"},"cell_type":"markdown","source":["### 2. When are the weights updated?\n","Whenever you train the network using batch means that you have chosen to train using batch gradient descent. There are three variants for gradient descent algorithm:\n","\n","Gradient Descent\n","Stochastic Gradient Descent\n","Batch Gradient Descent\n","The first one passes the whole data through the network and finds the error rate for all of them and finds the gradients with respect to all the data samples and updates the weights after passing the whole data-set. That means for each epoch, passing the whole data-set through the network, one update occurs. This update is accurate toward descending gradient.\n","\n","The second one, updates the weights after passing each data which means if your data sample has one thousand samples, one thousand updates will happen whilst the previous method updates the weights one time per the whole data-sample. This method is not accurate but is so much faster than the previous one.\n","\n","The last one tries to find a trade-off between the above approaches. You specify a batch size and you will update the weights after passing the data samples in each batch, means the gradients are calculated after passing each batch. Suppose you have one thousand data sample and you have specified a batch size with one hundred data sample. You will have 10 weight update for each epoch. This method is more accurate than the second approach and is more faster than the first approach.\n","\n","Do I back propagate after each batch has been presented to network or after each image?\n","\n","Your method is the last one. Consequently, after passing the entire batch, you would update the weights."]},{"metadata":{"id":"VYZKjj_I0Oom","colab_type":"code","colab":{}},"cell_type":"code","source":["# TODO: Please answer Question 2 below\n","reply = {'a': '', 'b':''}\n","\n","# Change see_correct_answer to 'True' to see expected answer \n","check_answer(reply, question=2, see_correct_answer=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"S3u2kRMd0cvi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"129daeeb-907b-4a35-bc32-da0f43869657","executionInfo":{"status":"ok","timestamp":1536589898441,"user_tz":-180,"elapsed":1412,"user":{"displayName":"Fernando Marcos Wittmann","photoUrl":"//lh5.googleusercontent.com/-IMybAdFO0xk/AAAAAAAAAAI/AAAAAAAAUuE/YzSiSBdfaIc/s50-c-k-no/photo.jpg","userId":"105799216615715799941"}}},"cell_type":"code","source":["b64encode(str(answer_1).encode('utf-8')) "],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["b'eydhJzogJycsICdiJzogJyd9'"]},"metadata":{"tags":[]},"execution_count":33}]},{"metadata":{"id":"aZMZMirk0eEf","colab_type":"code","colab":{}},"cell_type":"code","source":["from base64 import b64encode, b64decode"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nhX7QNVN1CnE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b925453e-e28d-4b9d-f9e4-8acdbaf6a6f8","executionInfo":{"status":"ok","timestamp":1536589619705,"user_tz":-180,"elapsed":918,"user":{"displayName":"Fernando Marcos Wittmann","photoUrl":"//lh5.googleusercontent.com/-IMybAdFO0xk/AAAAAAAAAAI/AAAAAAAAUuE/YzSiSBdfaIc/s50-c-k-no/photo.jpg","userId":"105799216615715799941"}}},"cell_type":"code","source":["b64decode(b'ZmVybmFuZG8ud2l0dG1hbm5AZ21haWwuY29t')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["b'fernando.wittmann@gmail.com'"]},"metadata":{"tags":[]},"execution_count":27}]},{"metadata":{"id":"dyg3q23l2oOD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"2983cdd9-7d47-49ed-ccf9-b0cc5579622f","executionInfo":{"status":"ok","timestamp":1536589587428,"user_tz":-180,"elapsed":2357,"user":{"displayName":"Fernando Marcos Wittmann","photoUrl":"//lh5.googleusercontent.com/-IMybAdFO0xk/AAAAAAAAAAI/AAAAAAAAUuE/YzSiSBdfaIc/s50-c-k-no/photo.jpg","userId":"105799216615715799941"}}},"cell_type":"code","source":["b64encode(b'fernando.wittmann@gmail.com')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["b'ZmVybmFuZG8ud2l0dG1hbm5AZ21haWwuY29t'"]},"metadata":{"tags":[]},"execution_count":24}]},{"metadata":{"id":"zz3FvpOl4DY-","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}