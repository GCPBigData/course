{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment-3-cats-dogs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WittmannF/course/blob/master/day-3/assignment-3-cats-dogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAJDdO1nECVt",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 3 - Cats vs Dogs Classifier\n",
        "In this project we are going to use transfer learning in order to buid a classifier to distinguish cats and dogs. As database, we will be using a subset from the Kaggle Competition: https://www.kaggle.com/c/dogs-vs-cats/. While the original dataset has 25000 images, you are going to use only 2000 images for training the model. As you will notice by the end of this project, thanks to transfer learning, we can get  great classification results even with smaller datasets. \n",
        "\n",
        "> **NOTE:** *Make sure to complete all the lines of code with a `TODO:` comment.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1F6h78evzxx",
        "colab_type": "text"
      },
      "source": [
        "## 1. Access the Dataset\n",
        "Run the cells bellow in order to mount your Google Drive (if using colab) and download the dataset. The dataset is also available to be manually downloaded in [this repository](https://github.com/dl7days/datasets).\n",
        "\n",
        "### 1.1 Mount Google Drive (if using Colab)\n",
        "Let's mount Google Drive in order to download the dataset. This way you won't have to always download again the dataset when accessing the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WizcoznMD1QD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys, os\n",
        "\n",
        "MOUNT_GDRIVE = True # Choose Google Drive\n",
        "USING_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "# Update here with the folder of the files of your course\n",
        "COURSE_DIRECTORY = '/content/drive/My Drive/course/day-3'\n",
        "\n",
        "if MOUNT_GDRIVE and USING_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    \n",
        "    # Create course directory if it doesn't exist (if not cloned from github)\n",
        "    if not os.path.exists(COURSE_DIRECTORY):\n",
        "        os.makedirs(COURSE_DIRECTORY)\n",
        "    # Open course directory\n",
        "    os.chdir(COURSE_DIRECTORY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdPvh7rwL3qL",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 Download Dataset\n",
        "Now, let's download the dataset if it is the first time you are running this cell (i.e., if the dataset folder was not found): "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcB3d5LJuurQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "DATA_PATH = 'cats-dogs-data/'\n",
        "DATA_URL = 'https://github.com/dl7days/datasets/raw/master/cats-dogs-data.zip'\n",
        "ZIP_FILENAME = 'cats-dogs-data.zip'\n",
        "\n",
        "if not os.path.exists(DATA_PATH):# If dataset folder doesn't exist\n",
        "    try: # Then try downloading and unzipping it\n",
        "        print(\"Downloading Dataset...\")\n",
        "        os.system(f\"wget {DATA_URL}\")\n",
        "\n",
        "        print(\"Unzipping Dataset\")\n",
        "        os.system(f\"unzip {ZIP_FILENAME}\")\n",
        "\n",
        "        print(\"Removing .zip file\")\n",
        "        os.system(f\"rm {ZIP_FILENAME}\")\n",
        "    except Exception as e: # If there's an error, ask to download manually\n",
        "        print(f\"Something went wrong. Please download the dataset manually at {DATA_URL}\")\n",
        "        print(f'The following exception was thrown:\\n{e}')\n",
        "else:\n",
        "    print(f'Dataset folder {DATA_PATH} has been found')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ67N2ItvH9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assign training and validation folders\n",
        "TRAIN_PATH = f'{DATA_PATH}train/'\n",
        "VALID_PATH = f'{DATA_PATH}valid/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD_mYk-xGX4L",
        "colab_type": "text"
      },
      "source": [
        "## 2. Visualize Images from the Dataset\n",
        "Now, let's visualize some of the images available in the training folder. First let's load a list with all filepaths:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fcs4CK_VX6mb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "\n",
        "filepaths = glob.glob(TRAIN_PATH+'/cat/*.jpg')\n",
        "for f in glob.glob(TRAIN_PATH+'/dog/*.jpg'):\n",
        "    filepaths.append(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A34eYZ2hGhIF",
        "colab_type": "text"
      },
      "source": [
        "Now, let's visualize a random image from the dataset. Every time you run the next cell, a random image (either of a dog or a cat) is going to be displayed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wk11nqgGf05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "import random\n",
        "\n",
        "load_img(random.choice(filepaths))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOI09Qqzlx2S",
        "colab_type": "text"
      },
      "source": [
        "## 3. Applying Transfer Learning\n",
        "\n",
        "### 3.1 Defining Image Data Generators\n",
        "Your first task is to define a training and a validation generator for loading the dataset. Follow those steps:\n",
        "1. First of al, you will choose any model of your choice in https://keras.io/applications to be imported (for example ResNet50)\n",
        "2. Next, import the model itself and the `preprocess_input` function (for example `from keras.applications.resnet50 import ResNet50, preprocess_input`)\n",
        "3. Import the ImageDataGenerator from the [image preprocessing module](https://keras.io/preprocessing/image/)\n",
        "4. Initialize the data generator class including the argument `preprocessing_function` as the `preprocess_input` function imported from the transfer learning model. This way all images are going to be preprocessed in the same settings of the images that were trained in the imported model.\n",
        "5. Define the training and validationg generators using the method `flow_from_directory`. \n",
        "    - Add the variables `TRAIN_PATH` and `VALID_PATH` as the path of each of each one. \n",
        "    - Set the dimension (224, 224) as the argument `target_size` (`TARGET_SHAPE[:2]` also works).\n",
        "    - As class mode, choose 'sparse'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G-a77IGP0b7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Import the model and the preprocess_input function\n",
        "\n",
        "\n",
        "# TODO: Import the ImageDataGenerator class\n",
        "\n",
        "\n",
        "# Shape in which all images are going to be reshaped\n",
        "TARGET_SHAPE = (224, 224, 3)\n",
        "\n",
        "# TODO: Initialize the data generator class \n",
        "datagen = ...\n",
        "\n",
        "# TODO: Create the training and validation generators using the method flow_from_directory\n",
        "train_gen = ...\n",
        "valid_gen = ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uE0aTWyP05v",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Defining Base Model\n",
        "Now you are going to define import a model from http://keras.io/applications, and add a fully connected layer in the end. When initializing the transfer learning model, make sure to set `input_shape` as (224, 224, 3) (or TARGET_SHAPE) and set `include_top` as False:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apAXKli0mBhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. TODO: Import any additional packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import ... # Import layers such as Dense, Flatten\n",
        "from keras.applications. ... import ... # Import your choice of transfer learning model\n",
        "\n",
        "# 2. TODO: Initialize base model\n",
        "base_model = ...\n",
        "\n",
        "# 3. TODO: Freeze layers from the base model\n",
        "for layer in base_model.layers:\n",
        "    ...\n",
        "    \n",
        "# 4. TODO: Add Fully connected layer to the base model\n",
        "model = Sequential([...\n",
        "                    ...\n",
        "                    ...])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_SPUWfNQMK6",
        "colab_type": "text"
      },
      "source": [
        "### 3.3 Training Model\n",
        "First let's compile the model. The optimizer and loss function as already been chosen for you. We are going to use as loss function `sparse_categorical_crossentropy` which is useful when the target contains classes represented as integer values (1 and 0 in our case). The learning rate of Adam was set to 1e-4 since the default value (1e-3) was too big and leading to unstabilities. We'll learning how to better define the learning rate in the next day. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0UuDNAZnar6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "model.compile(optimizer=Adam(lr=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmORPIQjGwgs",
        "colab_type": "text"
      },
      "source": [
        "Set the following inputs to the `fit_generator`:\n",
        "\n",
        "1. The training generator (`train_gen`)\n",
        "2. The number of batches (`train_gen.n//train_gen.batch_size`)\n",
        "3. The validation generator (`valid_gen`)\n",
        "4. The number of validation batches (`valid_gen.n//valid_gen.batch_size`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAEjtkiGsJGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Set the inputs for training the model using the generators\n",
        "model.fit_generator(generator=..., \n",
        "                    steps_per_epoch=..., \n",
        "                    epochs=3,\n",
        "                    validation_data=..., \n",
        "                    validation_steps=...)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_JmHJP6idT0",
        "colab_type": "text"
      },
      "source": [
        "## 4. Visualize Predictions\n",
        "Finally, let's confirm our model is predicting well by using online external sources. Find 5 urls to jpb images of either cats or dogs and fill the `URLS` list. For example:\n",
        "```\n",
        "URLS = ['http://example.com/image1.jpg',\n",
        "        'http://example.com/image2.jpg',\n",
        "        'http://example.com/image3.jpg',\n",
        "        'http://example.com/image4.jpg',\n",
        "        'http://example.com/image5.jpg']\n",
        "        \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pkh17zTyyzFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Fill with urls of jpg images \n",
        "URLS = ['...',\n",
        "        '...',\n",
        "        '...',\n",
        "        '...',\n",
        "        '...']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7cl4OIx7JVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "def predict_from_url(model, train_gen, url, target_shape=(224,224)):\n",
        "    \n",
        "    response = requests.get(url)\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "    img = img.resize(target_shape)\n",
        "\n",
        "    # Convert to a Numpy array\n",
        "    img_np = np.asarray(img)\n",
        "\n",
        "    # Reshape by adding 1 in the beginning to be compatible as input of the model\n",
        "    img_np = img_np[None] # https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html#numpy.newaxis\n",
        "\n",
        "    # Prepare the image for the model\n",
        "    img_np = preprocess_input(img_np)\n",
        "\n",
        "    # Decode output of model into classes and probabilities\n",
        "    result = model.predict(img_np)\n",
        " \n",
        "    class_indices = train_gen.class_indices    \n",
        "    index_to_class = {v: k for k, v in class_indices.items()}\n",
        "    \n",
        "    # Displaying image\n",
        "    plt.imshow(img)\n",
        "    plt.title(f'Predicted Class: {index_to_class[result.argmax()]}')\n",
        "    plt.show()\n",
        "    \n",
        "for url in URLS:\n",
        "    predict_from_url(model, train_gen, url, target_shape=TARGET_SHAPE[:2])  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}